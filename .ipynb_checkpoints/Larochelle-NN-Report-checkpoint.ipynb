{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from module_imports import *\n",
    "from download_data import *\n",
    "from import_data import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>binarize</th>\n",
       "      <th>gt</th>\n",
       "      <th>lt</th>\n",
       "      <th>vol</th>\n",
       "      <th>k</th>\n",
       "      <th>balance_labeled_data</th>\n",
       "      <th>vectorize_label</th>\n",
       "      <th>num_of_training_examples</th>\n",
       "      <th>features</th>\n",
       "      <th>...</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Reg</th>\n",
       "      <th>alpha</th>\n",
       "      <th>experiment_time</th>\n",
       "      <th>last_mean_training_loss</th>\n",
       "      <th>last_mean_validation_loss</th>\n",
       "      <th>last_mean_training_loss_slope</th>\n",
       "      <th>last_mean_validation_loss_slope</th>\n",
       "      <th>best_last_epoch</th>\n",
       "      <th>best_last_mean_validation_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>231</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>199</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2324</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>26.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>199</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2424</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>45.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>199</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1684</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>33.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>199</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>87</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>84</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>9</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>53</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1578</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>61.81</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2149</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>35.97</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>99</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>268</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>199</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>630</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>13.37</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>199</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2030</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>75.91</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.000599</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>3</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    source binarize  gt   lt   vol   k balance_labeled_data vectorize_label  \\\n",
       "81      GQ     True   1   20  1000   6                 True            True   \n",
       "110     GQ     True   1   50     0  23                False            True   \n",
       "111     GQ     True   0   50  1000  38                False            True   \n",
       "109     GQ     True   0   20  1000  25                False            True   \n",
       "89      GQ     True   1    5   100  87                 True            True   \n",
       "53      GQ     True   0   20   100  53                False            True   \n",
       "23      GQ     True   0  100     0  29                False            True   \n",
       "67      GQ     True   2  100  1000  70                 True            True   \n",
       "108     GQ     True   0    5     0  80                False            True   \n",
       "56      GQ     True   1   50   100  36                False            True   \n",
       "\n",
       "     num_of_training_examples  features               ...                \\\n",
       "81                        231         6               ...                 \n",
       "110                      2324        23               ...                 \n",
       "111                      2424        38               ...                 \n",
       "109                      1684        25               ...                 \n",
       "89                         84        87               ...                 \n",
       "53                       1578        53               ...                 \n",
       "23                       2149        29               ...                 \n",
       "67                        268        70               ...                 \n",
       "108                       630        80               ...                 \n",
       "56                       2030        36               ...                 \n",
       "\n",
       "     Lambda  Reg  alpha  experiment_time  last_mean_training_loss  \\\n",
       "81   0.0001   L2  0.001             8.89                     0.00   \n",
       "110  0.0100   L1  0.100            26.84                     0.51   \n",
       "111  0.0100   L2  0.010            45.80                     0.58   \n",
       "109  0.0100   L1  0.010            33.60                     0.52   \n",
       "89   0.0001   L2  0.100             3.18                     0.20   \n",
       "53   0.0001   L2  0.100            61.81                     0.12   \n",
       "23   0.0001   L2  0.001            35.97                     0.67   \n",
       "67   0.0100   L2  0.010            11.50                     0.43   \n",
       "108  0.0001   L1  0.001            13.37                     0.51   \n",
       "56   0.0001   L2  0.010            75.91                     0.36   \n",
       "\n",
       "    last_mean_validation_loss  last_mean_training_loss_slope  \\\n",
       "81                       0.00                       0.000000   \n",
       "110                      0.50                       0.000000   \n",
       "111                      0.55                      -0.000179   \n",
       "109                      0.55                      -0.000005   \n",
       "89                       0.90                       0.000000   \n",
       "53                       1.30                      -0.000066   \n",
       "23                       0.60                       0.001448   \n",
       "67                       0.60                      -0.000112   \n",
       "108                      0.60                       0.000170   \n",
       "56                       0.75                      -0.000599   \n",
       "\n",
       "     last_mean_validation_loss_slope  best_last_epoch  \\\n",
       "81                          0.000000              199   \n",
       "110                        -0.000023              199   \n",
       "111                        -0.000036              199   \n",
       "109                        -0.000020              199   \n",
       "89                          0.000112                9   \n",
       "53                          0.000248                1   \n",
       "23                         -0.000050               99   \n",
       "67                         -0.000012              199   \n",
       "108                        -0.000006              199   \n",
       "56                          0.000063                3   \n",
       "\n",
       "     best_last_mean_validation_loss  \n",
       "81                             0.00  \n",
       "110                            0.50  \n",
       "111                            0.55  \n",
       "109                            0.55  \n",
       "89                             0.58  \n",
       "53                             0.59  \n",
       "23                             0.60  \n",
       "67                             0.60  \n",
       "108                            0.60  \n",
       "56                             0.60  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_report_df = pd.read_csv('nn_report.csv')\n",
    "top_df = nn_report_df.sort(columns=['best_last_mean_validation_loss','last_mean_validation_loss_slope'], ascending=[True,True]).head(10)\n",
    "bottom_df = nn_report_df.sort(columns=['best_last_mean_validation_loss','last_mean_validation_loss_slope'], ascending=[True,True]).tail(10)\n",
    "#nn_report_df.sort(columns=['last_mean_validation_loss_slope','best_last_mean_validation_loss'], ascending=[True,True])\n",
    "top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source = GQ\n",
      "binarize = True\n",
      "gt = 0.0\n",
      "lt = 100.0\n",
      "vol = 1000\n",
      "k = 75\n",
      "balance_labeled_data = True\n",
      "vectorize_label = True\n",
      "num_of_training_examples = 294\n",
      "features = 75\n",
      "outputs = 2\n",
      "h1 = 51\n",
      "h2 = 51\n",
      "epochs = 100\n",
      "Lambda = 0.01\n",
      "Reg = L1\n",
      "alpha = 0.01\n",
      "experiment_time = 5.25\n",
      "last_mean_training_loss = 0.22\n",
      "last_mean_validation_loss = 1.1\n",
      "last_mean_training_loss_slope = -0.00154704651579\n",
      "last_mean_validation_loss_slope = 0.00220532307199\n",
      "best_last_epoch = 16.0\n",
      "best_last_mean_validation_loss = 0.58\n"
     ]
    }
   ],
   "source": [
    "cols = top_df.columns\n",
    "top_values = top_df.iloc[0].values\n",
    "for i in xrange(top_df.columns.shape[0]):\n",
    "    print cols[i],\"=\", top_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source ['GQ']\n",
      "binarize [True]\n",
      "gt [ 1.  0.  2.]\n",
      "lt [  50.   10.    5.  100.]\n",
      "vol [100000    100      0   1000  50000]\n",
      "k [33  1 69 56 34  3 37 28]\n",
      "balance_labeled_data [False]\n",
      "vectorize_label [True]\n",
      "num_of_training_examples [  21   24   20    8   23 1478 1318]\n",
      "features [33  1 69 56 34  3 37 28]\n",
      "outputs [2]\n",
      "h1 [31  1 11 29 14 25]\n",
      "h2 [31  1 11 29 14 25]\n",
      "epochs [30]\n",
      "Lambda [  1.00000000e-04   1.00000000e-01   1.00000000e-02   1.00000000e-03\n",
      "   1.00000000e+00]\n",
      "Reg ['L2' 'L1']\n",
      "alpha [ 0.1   0.01]\n",
      "experiment_time [ 0.36  0.34  0.32  0.38  0.33  0.4   9.47  8.16]\n",
      "last_mean_training_loss [ 0.02  0.04  0.05  0.1   0.17  0.22  0.66  0.5   0.43]\n",
      "last_mean_validation_loss [ 0.    0.03  0.06  0.14  0.2   0.21  0.43  0.44]\n",
      "last_mean_training_loss_slope [-0.0006798  -0.00114847 -0.00124023 -0.00270334 -0.00499569 -0.00504998\n",
      " -0.00514093 -0.00151341  0.00196465 -0.00090419]\n",
      "last_mean_validation_loss_slope [-0.00016092 -0.00075862 -0.00071648 -0.00141762 -0.00417241 -0.00457088\n",
      " -0.00467433 -0.00150575 -0.00056154 -0.00017381]\n",
      "best_last_epoch [ 29.   5.  20.]\n",
      "best_last_mean_validation_loss [ 0.    0.03  0.06  0.14  0.2   0.21  0.31  0.43]\n"
     ]
    }
   ],
   "source": [
    "for col in top_df.columns:\n",
    "    print col, top_df[col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>binarize</th>\n",
       "      <th>gt</th>\n",
       "      <th>lt</th>\n",
       "      <th>vol</th>\n",
       "      <th>features</th>\n",
       "      <th>outputs</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>epochs</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Reg</th>\n",
       "      <th>alpha</th>\n",
       "      <th>experiment_time</th>\n",
       "      <th>last_mean_training_loss</th>\n",
       "      <th>last_mean_validation_loss</th>\n",
       "      <th>last_mean_training_loss_slope</th>\n",
       "      <th>last_mean_validation_loss_slope</th>\n",
       "      <th>best_last_epoch</th>\n",
       "      <th>best_last_mean_validation_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>258.36</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.220820e-05</td>\n",
       "      <td>-3.106144e-05</td>\n",
       "      <td>499</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>251.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.27</td>\n",
       "      <td>6.118904e-06</td>\n",
       "      <td>-2.474107e-05</td>\n",
       "      <td>111</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>265.62</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-2.583922e-07</td>\n",
       "      <td>2.286391e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>270.70</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-8.425153e-06</td>\n",
       "      <td>4.902305e-06</td>\n",
       "      <td>234</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>266.22</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-2.067715e-05</td>\n",
       "      <td>5.635817e-06</td>\n",
       "      <td>16</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>255.78</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-3.944446e-06</td>\n",
       "      <td>6.636455e-06</td>\n",
       "      <td>42</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>250.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-1.621074e-05</td>\n",
       "      <td>4.442316e-05</td>\n",
       "      <td>71</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>248.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-2.122722e-05</td>\n",
       "      <td>-6.293041e-06</td>\n",
       "      <td>499</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>478.26</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-9.704056e-06</td>\n",
       "      <td>-3.649359e-06</td>\n",
       "      <td>799</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>252.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-4.150523e-06</td>\n",
       "      <td>-1.584077e-06</td>\n",
       "      <td>499</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source binarize  gt  lt  vol  features  outputs  h1  h2  epochs  Lambda  \\\n",
       "35      G     True   0  10    0        86        2   1   1     500  0.0001   \n",
       "23      G     True   0  10    0        86        2   1   1     500  0.0000   \n",
       "53      G     True   0  10    0        86        2   1   1     500  0.0100   \n",
       "13      G     True   0  10    0        86        2   1   1     500  0.0000   \n",
       "17      G     True   0  10    0        86        2   1   1     500  0.0000   \n",
       "29      G     True   0  10    0        86        2   1   1     500  0.0001   \n",
       "21      G     True   0  10    0        86        2   1   1     500  0.0000   \n",
       "31      G     True   0  10    0        86        2   1   1     500  0.0001   \n",
       "0       G     True   0  10    0        85        2  10  10     800  0.0100   \n",
       "32      G     True   0  10    0        86        2   1   1     500  0.0001   \n",
       "\n",
       "   Reg   alpha  experiment_time  last_mean_training_loss  \\\n",
       "35  L1  0.1000           258.36                     0.17   \n",
       "23  L1  0.1000           251.11                     0.18   \n",
       "53  L2  0.0100           265.62                     0.19   \n",
       "13  L2  0.0010           270.70                     0.18   \n",
       "17  L2  0.1000           266.22                     0.17   \n",
       "29  L2  0.1000           255.78                     0.17   \n",
       "21  L1  0.0100           250.83                     0.17   \n",
       "31  L1  0.0001           248.10                     0.20   \n",
       "0   L2  0.0001           478.26                     0.19   \n",
       "32  L1  0.0010           252.00                     0.19   \n",
       "\n",
       "    last_mean_validation_loss  last_mean_training_loss_slope  \\\n",
       "35                       0.25                  -1.220820e-05   \n",
       "23                       0.27                   6.118904e-06   \n",
       "53                       0.27                  -2.583922e-07   \n",
       "13                       0.26                  -8.425153e-06   \n",
       "17                       0.29                  -2.067715e-05   \n",
       "29                       0.29                  -3.944446e-06   \n",
       "21                       0.31                  -1.621074e-05   \n",
       "31                       0.27                  -2.122722e-05   \n",
       "0                        0.27                  -9.704056e-06   \n",
       "32                       0.27                  -4.150523e-06   \n",
       "\n",
       "    last_mean_validation_loss_slope  best_last_epoch  \\\n",
       "35                    -3.106144e-05              499   \n",
       "23                    -2.474107e-05              111   \n",
       "53                     2.286391e-07                1   \n",
       "13                     4.902305e-06              234   \n",
       "17                     5.635817e-06               16   \n",
       "29                     6.636455e-06               42   \n",
       "21                     4.442316e-05               71   \n",
       "31                    -6.293041e-06              499   \n",
       "0                     -3.649359e-06              799   \n",
       "32                    -1.584077e-06              499   \n",
       "\n",
       "    best_last_mean_validation_loss  \n",
       "35                            0.25  \n",
       "23                            0.26  \n",
       "53                            0.26  \n",
       "13                            0.26  \n",
       "17                            0.26  \n",
       "29                            0.26  \n",
       "21                            0.26  \n",
       "31                            0.27  \n",
       "0                             0.27  \n",
       "32                            0.27  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_report_df = pd.read_csv('gridsearch2-nn_report.csv')\n",
    "top_df = nn_report_df.sort(columns=['best_last_mean_validation_loss','last_mean_validation_loss_slope'], ascending=[True,True]).head(10)\n",
    "#nn_report_df.sort(columns=['last_mean_validation_loss_slope','best_last_mean_validation_loss'], ascending=[True,True])\n",
    "top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>binarize</th>\n",
       "      <th>gt</th>\n",
       "      <th>lt</th>\n",
       "      <th>vol</th>\n",
       "      <th>k</th>\n",
       "      <th>balance_labeled_data</th>\n",
       "      <th>vectorize_label</th>\n",
       "      <th>num_of_training_examples</th>\n",
       "      <th>features</th>\n",
       "      <th>...</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Reg</th>\n",
       "      <th>alpha</th>\n",
       "      <th>experiment_time</th>\n",
       "      <th>last_mean_training_loss</th>\n",
       "      <th>last_mean_validation_loss</th>\n",
       "      <th>last_mean_training_loss_slope</th>\n",
       "      <th>last_mean_validation_loss_slope</th>\n",
       "      <th>best_last_epoch</th>\n",
       "      <th>best_last_mean_validation_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2436</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2436</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>403</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.012644</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>534</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>-0.002262</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>636</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>636</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1116</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2204</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.000734</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1456</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2751</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.64</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.001028</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source binarize  gt   lt   vol   k balance_labeled_data vectorize_label  \\\n",
       "3      GQ     True   0   50  1000  29                False            True   \n",
       "15     GQ     True   0   50  1000   4                False            True   \n",
       "16     GQ     True   2    5     0  88                False            True   \n",
       "8      GQ     True   1    5     0   9                False            True   \n",
       "25     GQ     True   0    5   100  37                False            True   \n",
       "23     GQ     True   0    5   100  29                False            True   \n",
       "29     GQ     True   1   10     0  22                False            True   \n",
       "7      GQ     True   2   50   100  29                False            True   \n",
       "13     GQ     True   2   20   100  33                False            True   \n",
       "6      GQ     True   0  100   100  14                False            True   \n",
       "\n",
       "    num_of_training_examples  features               ...                \\\n",
       "3                       2436        29               ...                 \n",
       "15                      2436         4               ...                 \n",
       "16                       403        88               ...                 \n",
       "8                        534         9               ...                 \n",
       "25                       636        37               ...                 \n",
       "23                       636        29               ...                 \n",
       "29                      1116        22               ...                 \n",
       "7                       2204        29               ...                 \n",
       "13                      1456        33               ...                 \n",
       "6                       2751        14               ...                 \n",
       "\n",
       "    Lambda  Reg   alpha  experiment_time  last_mean_training_loss  \\\n",
       "3   0.0010   L1  0.0100             4.24                     0.70   \n",
       "15  0.0100   L2  0.0010             4.18                     0.69   \n",
       "16  0.0001   L1  0.0100             1.39                     0.62   \n",
       "8   0.0010   L1  0.0010             1.14                     0.70   \n",
       "25  0.0001   L1  0.1000             1.31                     0.49   \n",
       "23  1.0000   L2  0.0010             1.31                     0.70   \n",
       "29  1.0000   L2  0.0001             2.34                     0.70   \n",
       "7   0.0010   L2  0.0001             4.26                     0.71   \n",
       "13  0.0100   L1  0.0001             2.94                     0.72   \n",
       "6   0.0010   L1  0.0001             4.64                     0.72   \n",
       "\n",
       "   last_mean_validation_loss  last_mean_training_loss_slope  \\\n",
       "3                       0.69                      -0.000180   \n",
       "15                      0.70                      -0.000051   \n",
       "16                      0.71                      -0.012644   \n",
       "8                       0.74                      -0.000285   \n",
       "25                      1.01                      -0.003708   \n",
       "23                      0.69                      -0.000208   \n",
       "29                      0.69                      -0.000267   \n",
       "7                       0.67                      -0.000734   \n",
       "13                      0.63                      -0.000988   \n",
       "6                       0.62                      -0.001028   \n",
       "\n",
       "    last_mean_validation_loss_slope  best_last_epoch  \\\n",
       "3                          0.000083        17.000000   \n",
       "15                        -0.000331        19.000000   \n",
       "16                         0.000310        16.000000   \n",
       "8                         -0.002262        19.000000   \n",
       "25                         0.001612         6.000000   \n",
       "23                         0.000036             -inf   \n",
       "29                         0.000160             -inf   \n",
       "7                          0.000778             -inf   \n",
       "13                         0.002834             -inf   \n",
       "6                          0.002993             -inf   \n",
       "\n",
       "    best_last_mean_validation_loss  \n",
       "3                         0.690000  \n",
       "15                        0.700000  \n",
       "16                        0.710000  \n",
       "8                         0.740000  \n",
       "25                        0.750000  \n",
       "23                             inf  \n",
       "29                             inf  \n",
       "7                              inf  \n",
       "13                             inf  \n",
       "6                              inf  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source []\n",
      "binarize []\n",
      "gt []\n",
      "lt []\n",
      "vol []\n",
      "k []\n",
      "balance_labeled_data []\n",
      "vectorize_label []\n",
      "num_of_training_examples []\n",
      "features []\n",
      "outputs []\n",
      "h1 []\n",
      "h2 []\n",
      "epochs []\n",
      "Lambda []\n",
      "Reg []\n",
      "alpha []\n",
      "experiment_time []\n",
      "last_mean_training_loss []\n",
      "last_mean_validation_loss []\n",
      "last_mean_training_loss_slope []\n",
      "last_mean_validation_loss_slope []\n",
      "best_last_epoch []\n",
      "best_last_mean_validation_loss []\n"
     ]
    }
   ],
   "source": [
    "for col in bottom_df.columns:\n",
    "    print col, bottom_df[col].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q,True,0,50.0,0,10,2\n",
    "#h1: 2 h2: 2 epochs: 20 Lambda: 1.0 Reg: L2 alpha: 1.0   <--- alpha was the culprit\n",
    "# np.isnan(W1[0])[0] == True) == True\n",
    "# EPOCH 0\n",
    "\n",
    "# -0.1 blows everything up too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
