{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from module_imports import *\n",
    "from download_data import *\n",
    "from import_data import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>binarize</th>\n",
       "      <th>gt</th>\n",
       "      <th>lt</th>\n",
       "      <th>vol</th>\n",
       "      <th>k</th>\n",
       "      <th>balance_labeled_data</th>\n",
       "      <th>vectorize_label</th>\n",
       "      <th>num_of_training_examples</th>\n",
       "      <th>features</th>\n",
       "      <th>...</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Reg</th>\n",
       "      <th>alpha</th>\n",
       "      <th>experiment_time</th>\n",
       "      <th>last_mean_training_loss</th>\n",
       "      <th>last_mean_validation_loss</th>\n",
       "      <th>last_mean_training_loss_slope</th>\n",
       "      <th>last_mean_validation_loss_slope</th>\n",
       "      <th>best_last_epoch</th>\n",
       "      <th>best_last_mean_validation_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>443</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>38.44</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-5.479956e-07</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1038</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>114.43</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.033360e-04</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>499</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>343</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>40.22</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2.562673e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>13</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>683</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-1.672260e-03</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>18</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1038</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>16.41</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>3.157427e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1038</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>153.56</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-1.790749e-05</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>443</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>6.27</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.994524e-04</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>5</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>783</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.338499e-04</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>49</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>893</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>106.83</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-6.897232e-05</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>9</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1038</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>119.28</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.192003e-03</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>5</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source binarize  gt   lt   vol   k balance_labeled_data vectorize_label  \\\n",
       "13     GQ     True   0    5   100  18                False            True   \n",
       "14     GQ     True   1  100     0  17                False            True   \n",
       "26     GQ     True   1    5     0  23                False            True   \n",
       "31     GQ     True   1   10     0  21                False            True   \n",
       "3      GQ     True   1  100     0  59                False            True   \n",
       "24     GQ     True   1   50   100  82                False            True   \n",
       "5      GQ     True   0    5     0  81                False            True   \n",
       "33     GQ     True   0   10  1000  86                False            True   \n",
       "20     GQ     True   1   20   100  30                False            True   \n",
       "23     GQ     True   1   50   100  15                False            True   \n",
       "\n",
       "    num_of_training_examples  features               ...                \\\n",
       "13                       443        18               ...                 \n",
       "14                      1038        17               ...                 \n",
       "26                       343        23               ...                 \n",
       "31                       683        21               ...                 \n",
       "3                       1038        59               ...                 \n",
       "24                      1038        82               ...                 \n",
       "5                        443        81               ...                 \n",
       "33                       783        86               ...                 \n",
       "20                       893        30               ...                 \n",
       "23                      1038        15               ...                 \n",
       "\n",
       "    Lambda  Reg   alpha  experiment_time  last_mean_training_loss  \\\n",
       "13  0.0010   L1  0.1000            38.44                     0.03   \n",
       "14  0.0100   L2  0.0001           114.43                     0.40   \n",
       "26  0.0001   L2  0.0010            40.22                     0.26   \n",
       "31  0.0001   L2  0.0100             5.03                     0.45   \n",
       "3   0.0100   L2  0.1000            16.41                     0.69   \n",
       "24  0.0001   L1  0.0100           153.56                     0.03   \n",
       "5   0.1000   L2  0.0010             6.27                     0.54   \n",
       "33  0.0010   L1  0.0010             9.09                     0.64   \n",
       "20  0.0100   L2  0.0100           106.83                     0.07   \n",
       "23  0.0100   L2  0.0010           119.28                     0.70   \n",
       "\n",
       "   last_mean_validation_loss  last_mean_training_loss_slope  \\\n",
       "13                      1.06                  -5.479956e-07   \n",
       "14                      0.61                  -1.033360e-04   \n",
       "26                      0.71                   2.562673e-06   \n",
       "31                      0.64                  -1.672260e-03   \n",
       "3                       0.69                   3.157427e-05   \n",
       "24                      1.25                  -1.790749e-05   \n",
       "5                       0.70                   8.994524e-04   \n",
       "33                      0.65                  -1.338499e-04   \n",
       "20                      0.86                  -6.897232e-05   \n",
       "23                      0.85                   1.192003e-03   \n",
       "\n",
       "    last_mean_validation_loss_slope  best_last_epoch  \\\n",
       "13                         0.000014                1   \n",
       "14                        -0.000002              499   \n",
       "26                         0.000008               13   \n",
       "31                         0.000236               18   \n",
       "3                          0.000024                1   \n",
       "24                         0.000025                1   \n",
       "5                          0.000080                5   \n",
       "33                        -0.000217               49   \n",
       "20                         0.000012                9   \n",
       "23                         0.000013                5   \n",
       "\n",
       "    best_last_mean_validation_loss  \n",
       "13                            0.59  \n",
       "14                            0.61  \n",
       "26                            0.61  \n",
       "31                            0.63  \n",
       "3                             0.64  \n",
       "24                            0.64  \n",
       "5                             0.64  \n",
       "33                            0.65  \n",
       "20                            0.65  \n",
       "23                            0.65  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_report_df = pd.read_csv('nn_report.csv')\n",
    "top_df = nn_report_df.sort(columns=['best_last_mean_validation_loss','last_mean_validation_loss_slope'], ascending=[True,True]).head(10)\n",
    "bottom_df = nn_report_df.sort(columns=['best_last_mean_validation_loss','last_mean_validation_loss_slope'], ascending=[True,True]).tail(10)\n",
    "#nn_report_df.sort(columns=['last_mean_validation_loss_slope','best_last_mean_validation_loss'], ascending=[True,True])\n",
    "top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source = GQ\n",
      "binarize = True\n",
      "gt = 0.0\n",
      "lt = 100.0\n",
      "vol = 1000\n",
      "k = 75\n",
      "balance_labeled_data = True\n",
      "vectorize_label = True\n",
      "num_of_training_examples = 294\n",
      "features = 75\n",
      "outputs = 2\n",
      "h1 = 51\n",
      "h2 = 51\n",
      "epochs = 100\n",
      "Lambda = 0.01\n",
      "Reg = L1\n",
      "alpha = 0.01\n",
      "experiment_time = 5.25\n",
      "last_mean_training_loss = 0.22\n",
      "last_mean_validation_loss = 1.1\n",
      "last_mean_training_loss_slope = -0.00154704651579\n",
      "last_mean_validation_loss_slope = 0.00220532307199\n",
      "best_last_epoch = 16.0\n",
      "best_last_mean_validation_loss = 0.58\n"
     ]
    }
   ],
   "source": [
    "cols = top_df.columns\n",
    "top_values = top_df.iloc[0].values\n",
    "for i in xrange(top_df.columns.shape[0]):\n",
    "    print cols[i],\"=\", top_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source ['GQ']\n",
      "binarize [True]\n",
      "gt [ 1.  0.  2.]\n",
      "lt [  50.   10.    5.  100.]\n",
      "vol [100000    100      0   1000  50000]\n",
      "k [33  1 69 56 34  3 37 28]\n",
      "balance_labeled_data [False]\n",
      "vectorize_label [True]\n",
      "num_of_training_examples [  21   24   20    8   23 1478 1318]\n",
      "features [33  1 69 56 34  3 37 28]\n",
      "outputs [2]\n",
      "h1 [31  1 11 29 14 25]\n",
      "h2 [31  1 11 29 14 25]\n",
      "epochs [30]\n",
      "Lambda [  1.00000000e-04   1.00000000e-01   1.00000000e-02   1.00000000e-03\n",
      "   1.00000000e+00]\n",
      "Reg ['L2' 'L1']\n",
      "alpha [ 0.1   0.01]\n",
      "experiment_time [ 0.36  0.34  0.32  0.38  0.33  0.4   9.47  8.16]\n",
      "last_mean_training_loss [ 0.02  0.04  0.05  0.1   0.17  0.22  0.66  0.5   0.43]\n",
      "last_mean_validation_loss [ 0.    0.03  0.06  0.14  0.2   0.21  0.43  0.44]\n",
      "last_mean_training_loss_slope [-0.0006798  -0.00114847 -0.00124023 -0.00270334 -0.00499569 -0.00504998\n",
      " -0.00514093 -0.00151341  0.00196465 -0.00090419]\n",
      "last_mean_validation_loss_slope [-0.00016092 -0.00075862 -0.00071648 -0.00141762 -0.00417241 -0.00457088\n",
      " -0.00467433 -0.00150575 -0.00056154 -0.00017381]\n",
      "best_last_epoch [ 29.   5.  20.]\n",
      "best_last_mean_validation_loss [ 0.    0.03  0.06  0.14  0.2   0.21  0.31  0.43]\n"
     ]
    }
   ],
   "source": [
    "for col in top_df.columns:\n",
    "    print col, top_df[col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>binarize</th>\n",
       "      <th>gt</th>\n",
       "      <th>lt</th>\n",
       "      <th>vol</th>\n",
       "      <th>features</th>\n",
       "      <th>outputs</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>epochs</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Reg</th>\n",
       "      <th>alpha</th>\n",
       "      <th>experiment_time</th>\n",
       "      <th>last_mean_training_loss</th>\n",
       "      <th>last_mean_validation_loss</th>\n",
       "      <th>last_mean_training_loss_slope</th>\n",
       "      <th>last_mean_validation_loss_slope</th>\n",
       "      <th>best_last_epoch</th>\n",
       "      <th>best_last_mean_validation_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>258.36</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.220820e-05</td>\n",
       "      <td>-3.106144e-05</td>\n",
       "      <td>499</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>251.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.27</td>\n",
       "      <td>6.118904e-06</td>\n",
       "      <td>-2.474107e-05</td>\n",
       "      <td>111</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>265.62</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-2.583922e-07</td>\n",
       "      <td>2.286391e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>270.70</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-8.425153e-06</td>\n",
       "      <td>4.902305e-06</td>\n",
       "      <td>234</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>266.22</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-2.067715e-05</td>\n",
       "      <td>5.635817e-06</td>\n",
       "      <td>16</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>255.78</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-3.944446e-06</td>\n",
       "      <td>6.636455e-06</td>\n",
       "      <td>42</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>250.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-1.621074e-05</td>\n",
       "      <td>4.442316e-05</td>\n",
       "      <td>71</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>248.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-2.122722e-05</td>\n",
       "      <td>-6.293041e-06</td>\n",
       "      <td>499</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>478.26</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-9.704056e-06</td>\n",
       "      <td>-3.649359e-06</td>\n",
       "      <td>799</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>252.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-4.150523e-06</td>\n",
       "      <td>-1.584077e-06</td>\n",
       "      <td>499</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source binarize  gt  lt  vol  features  outputs  h1  h2  epochs  Lambda  \\\n",
       "35      G     True   0  10    0        86        2   1   1     500  0.0001   \n",
       "23      G     True   0  10    0        86        2   1   1     500  0.0000   \n",
       "53      G     True   0  10    0        86        2   1   1     500  0.0100   \n",
       "13      G     True   0  10    0        86        2   1   1     500  0.0000   \n",
       "17      G     True   0  10    0        86        2   1   1     500  0.0000   \n",
       "29      G     True   0  10    0        86        2   1   1     500  0.0001   \n",
       "21      G     True   0  10    0        86        2   1   1     500  0.0000   \n",
       "31      G     True   0  10    0        86        2   1   1     500  0.0001   \n",
       "0       G     True   0  10    0        85        2  10  10     800  0.0100   \n",
       "32      G     True   0  10    0        86        2   1   1     500  0.0001   \n",
       "\n",
       "   Reg   alpha  experiment_time  last_mean_training_loss  \\\n",
       "35  L1  0.1000           258.36                     0.17   \n",
       "23  L1  0.1000           251.11                     0.18   \n",
       "53  L2  0.0100           265.62                     0.19   \n",
       "13  L2  0.0010           270.70                     0.18   \n",
       "17  L2  0.1000           266.22                     0.17   \n",
       "29  L2  0.1000           255.78                     0.17   \n",
       "21  L1  0.0100           250.83                     0.17   \n",
       "31  L1  0.0001           248.10                     0.20   \n",
       "0   L2  0.0001           478.26                     0.19   \n",
       "32  L1  0.0010           252.00                     0.19   \n",
       "\n",
       "    last_mean_validation_loss  last_mean_training_loss_slope  \\\n",
       "35                       0.25                  -1.220820e-05   \n",
       "23                       0.27                   6.118904e-06   \n",
       "53                       0.27                  -2.583922e-07   \n",
       "13                       0.26                  -8.425153e-06   \n",
       "17                       0.29                  -2.067715e-05   \n",
       "29                       0.29                  -3.944446e-06   \n",
       "21                       0.31                  -1.621074e-05   \n",
       "31                       0.27                  -2.122722e-05   \n",
       "0                        0.27                  -9.704056e-06   \n",
       "32                       0.27                  -4.150523e-06   \n",
       "\n",
       "    last_mean_validation_loss_slope  best_last_epoch  \\\n",
       "35                    -3.106144e-05              499   \n",
       "23                    -2.474107e-05              111   \n",
       "53                     2.286391e-07                1   \n",
       "13                     4.902305e-06              234   \n",
       "17                     5.635817e-06               16   \n",
       "29                     6.636455e-06               42   \n",
       "21                     4.442316e-05               71   \n",
       "31                    -6.293041e-06              499   \n",
       "0                     -3.649359e-06              799   \n",
       "32                    -1.584077e-06              499   \n",
       "\n",
       "    best_last_mean_validation_loss  \n",
       "35                            0.25  \n",
       "23                            0.26  \n",
       "53                            0.26  \n",
       "13                            0.26  \n",
       "17                            0.26  \n",
       "29                            0.26  \n",
       "21                            0.26  \n",
       "31                            0.27  \n",
       "0                             0.27  \n",
       "32                            0.27  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_report_df = pd.read_csv('gridsearch2-nn_report.csv')\n",
    "top_df = nn_report_df.sort(columns=['best_last_mean_validation_loss','last_mean_validation_loss_slope'], ascending=[True,True]).head(10)\n",
    "#nn_report_df.sort(columns=['last_mean_validation_loss_slope','best_last_mean_validation_loss'], ascending=[True,True])\n",
    "top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>binarize</th>\n",
       "      <th>gt</th>\n",
       "      <th>lt</th>\n",
       "      <th>vol</th>\n",
       "      <th>k</th>\n",
       "      <th>balance_labeled_data</th>\n",
       "      <th>vectorize_label</th>\n",
       "      <th>num_of_training_examples</th>\n",
       "      <th>features</th>\n",
       "      <th>...</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Reg</th>\n",
       "      <th>alpha</th>\n",
       "      <th>experiment_time</th>\n",
       "      <th>last_mean_training_loss</th>\n",
       "      <th>last_mean_validation_loss</th>\n",
       "      <th>last_mean_training_loss_slope</th>\n",
       "      <th>last_mean_validation_loss_slope</th>\n",
       "      <th>best_last_epoch</th>\n",
       "      <th>best_last_mean_validation_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2436</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2436</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>403</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.012644</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>534</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>-0.002262</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>636</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>636</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1116</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2204</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.000734</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1456</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2751</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.64</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.001028</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source binarize  gt   lt   vol   k balance_labeled_data vectorize_label  \\\n",
       "3      GQ     True   0   50  1000  29                False            True   \n",
       "15     GQ     True   0   50  1000   4                False            True   \n",
       "16     GQ     True   2    5     0  88                False            True   \n",
       "8      GQ     True   1    5     0   9                False            True   \n",
       "25     GQ     True   0    5   100  37                False            True   \n",
       "23     GQ     True   0    5   100  29                False            True   \n",
       "29     GQ     True   1   10     0  22                False            True   \n",
       "7      GQ     True   2   50   100  29                False            True   \n",
       "13     GQ     True   2   20   100  33                False            True   \n",
       "6      GQ     True   0  100   100  14                False            True   \n",
       "\n",
       "    num_of_training_examples  features               ...                \\\n",
       "3                       2436        29               ...                 \n",
       "15                      2436         4               ...                 \n",
       "16                       403        88               ...                 \n",
       "8                        534         9               ...                 \n",
       "25                       636        37               ...                 \n",
       "23                       636        29               ...                 \n",
       "29                      1116        22               ...                 \n",
       "7                       2204        29               ...                 \n",
       "13                      1456        33               ...                 \n",
       "6                       2751        14               ...                 \n",
       "\n",
       "    Lambda  Reg   alpha  experiment_time  last_mean_training_loss  \\\n",
       "3   0.0010   L1  0.0100             4.24                     0.70   \n",
       "15  0.0100   L2  0.0010             4.18                     0.69   \n",
       "16  0.0001   L1  0.0100             1.39                     0.62   \n",
       "8   0.0010   L1  0.0010             1.14                     0.70   \n",
       "25  0.0001   L1  0.1000             1.31                     0.49   \n",
       "23  1.0000   L2  0.0010             1.31                     0.70   \n",
       "29  1.0000   L2  0.0001             2.34                     0.70   \n",
       "7   0.0010   L2  0.0001             4.26                     0.71   \n",
       "13  0.0100   L1  0.0001             2.94                     0.72   \n",
       "6   0.0010   L1  0.0001             4.64                     0.72   \n",
       "\n",
       "   last_mean_validation_loss  last_mean_training_loss_slope  \\\n",
       "3                       0.69                      -0.000180   \n",
       "15                      0.70                      -0.000051   \n",
       "16                      0.71                      -0.012644   \n",
       "8                       0.74                      -0.000285   \n",
       "25                      1.01                      -0.003708   \n",
       "23                      0.69                      -0.000208   \n",
       "29                      0.69                      -0.000267   \n",
       "7                       0.67                      -0.000734   \n",
       "13                      0.63                      -0.000988   \n",
       "6                       0.62                      -0.001028   \n",
       "\n",
       "    last_mean_validation_loss_slope  best_last_epoch  \\\n",
       "3                          0.000083        17.000000   \n",
       "15                        -0.000331        19.000000   \n",
       "16                         0.000310        16.000000   \n",
       "8                         -0.002262        19.000000   \n",
       "25                         0.001612         6.000000   \n",
       "23                         0.000036             -inf   \n",
       "29                         0.000160             -inf   \n",
       "7                          0.000778             -inf   \n",
       "13                         0.002834             -inf   \n",
       "6                          0.002993             -inf   \n",
       "\n",
       "    best_last_mean_validation_loss  \n",
       "3                         0.690000  \n",
       "15                        0.700000  \n",
       "16                        0.710000  \n",
       "8                         0.740000  \n",
       "25                        0.750000  \n",
       "23                             inf  \n",
       "29                             inf  \n",
       "7                              inf  \n",
       "13                             inf  \n",
       "6                              inf  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source []\n",
      "binarize []\n",
      "gt []\n",
      "lt []\n",
      "vol []\n",
      "k []\n",
      "balance_labeled_data []\n",
      "vectorize_label []\n",
      "num_of_training_examples []\n",
      "features []\n",
      "outputs []\n",
      "h1 []\n",
      "h2 []\n",
      "epochs []\n",
      "Lambda []\n",
      "Reg []\n",
      "alpha []\n",
      "experiment_time []\n",
      "last_mean_training_loss []\n",
      "last_mean_validation_loss []\n",
      "last_mean_training_loss_slope []\n",
      "last_mean_validation_loss_slope []\n",
      "best_last_epoch []\n",
      "best_last_mean_validation_loss []\n"
     ]
    }
   ],
   "source": [
    "for col in bottom_df.columns:\n",
    "    print col, bottom_df[col].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q,True,0,50.0,0,10,2\n",
    "#h1: 2 h2: 2 epochs: 20 Lambda: 1.0 Reg: L2 alpha: 1.0   <--- alpha was the culprit\n",
    "# np.isnan(W1[0])[0] == True) == True\n",
    "# EPOCH 0\n",
    "\n",
    "# -0.1 blows everything up too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
